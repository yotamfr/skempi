{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yotamfr/development/skempi/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skempi_consts import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload   \n",
    "%autoreload 2\n",
    "\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "df = skempi_df\n",
    "ddg1 = df[df.Protein.isin(G1)].DDG.values\n",
    "ddg2 = df[df.Protein.isin(G2)].DDG.values\n",
    "ddg3 = df[df.Protein.isin(G3)].DDG.values\n",
    "ddg4 = df[df.Protein.isin(G4)].DDG.values\n",
    "ddg5 = df[df.Protein.isin(G5)].DDG.values\n",
    "\n",
    "ddg1235 = df[df.Protein.isin(G1 + G2 + G3 + G5)].DDG.values\n",
    "\n",
    "# plt.hist(ddg1, bins=100, alpha=0.5, label=\"G1\", normed=1, cumulative=False, histtype='bar')\n",
    "# plt.hist(ddg2, bins=100, alpha=0.5, label=\"G2\", normed=1, cumulative=False, histtype='bar')\n",
    "# plt.hist(ddg3, bins=100, alpha=0.5, label=\"G3\", normed=1, cumulative=False, histtype='bar')\n",
    "plt.hist(ddg4, bins=100, alpha=0.5, label=\"G4\", normed=1, cumulative=False, histtype='bar')\n",
    "# plt.hist(ddg5, bins=100, alpha=0.5, label=\"G5\", normed=1, cumulative=False, histtype='bar')\n",
    "\n",
    "plt.hist(ddg1235, bins=100, alpha=0.5, label=\"G1235\", normed=1, cumulative=False, histtype='bar')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"DDG Distribution\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skempi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skempi_utils import *\n",
    "import skempi_consts as consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mut = 0\n",
    "pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "for i, row in skempi_df.iterrows():\n",
    "    num_mut += len(row[\"Mutation(s)_cleaned\"].split(','))\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "num_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_temperature_array(records, agg=np.min):\n",
    "    arr = []\n",
    "    pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "    for i, row in skempi_df.iterrows():\n",
    "        arr_obs_mut = []\n",
    "        for mutation in row[\"Mutation(s)_cleaned\"].split(','):\n",
    "            mut = Mutation(mutation)\n",
    "            res_i, chain_id = mut.i, mut.chain_id\n",
    "            t = tuple(row.Protein.split('_'))\n",
    "            skempi_record = records[t]\n",
    "            res = skempi_record[chain_id][res_i]\n",
    "            temps = [a.temp for a in res.atoms]\n",
    "            arr_obs_mut.append(np.mean(temps))\n",
    "        arr.append(agg(arr_obs_mut))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return arr\n",
    "\n",
    "skempi_records = load_skempi_structs(pdb_path=\"../data/pdbs_n\", compute_dist_mat=True)\n",
    "all_features[\"B-factor\"] = temp_arr = get_temperature_array(skempi_records, agg=np.min)\n",
    "pearsonr(temp_arr, skempi_df.DDG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aaindex import *\n",
    "B = BLOSUM62\n",
    "C = SKOJ970101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skempi_records = load_skempi_structs(pdb_path=\"../data/pdbs\", compute_dist_mat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def comp_ei(mut, skempi_record, B, radius):\n",
    "    P = skempi_record.get_profile(mut.chain_id)\n",
    "    return EI(mut.m, mut.w, P, mut.i, B)\n",
    "\n",
    "\n",
    "def comp_cp(mut, skempi_record, C, radius):\n",
    "    return CP(mut, skempi_record, C, radius)\n",
    "\n",
    "\n",
    "def get_ddg_ei_cp_arrays(M, func, radius=None):\n",
    "    arr_ddg = []\n",
    "    arr_obs = []\n",
    "    pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "    for i, row in skempi_df.iterrows():\n",
    "        ddg = row.DDG\n",
    "        arr_ddg.append(ddg)\n",
    "        arr_obs_mut = []\n",
    "        for mutation in row[\"Mutation(s)_cleaned\"].split(','):\n",
    "            mut = Mutation(mutation)\n",
    "            t = tuple(row.Protein.split('_'))\n",
    "            skempi_record = skempi_records[t]\n",
    "            obs = func(mut, skempi_record, M, radius)\n",
    "            arr_obs_mut.append(obs)\n",
    "        arr_obs.append(np.sum(arr_obs_mut))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return arr_ddg, arr_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def grid_search_cp(matrices=[SKOJ970101, BASU010101], radiuses=[4, 5, 6, 7, 8, 9, 10]):\n",
    "    res_dict = {}\n",
    "    for C, angs in product(matrices, radiuses):\n",
    "        key = (str(C), angs)\n",
    "        arr_ddg, arr_cp = get_ddg_ei_cp_arrays(C, comp_cp, angs)\n",
    "        res_dict[key] = (arr_ddg, arr_cp)\n",
    "        cor_cp = pearsonr(arr_ddg, arr_cp)\n",
    "        print(\"%s: CP: %s\" % (key, cor_cp,))\n",
    "    return res_dict\n",
    "\n",
    "def grid_search_ei(matrices=[BLOSUM62, SKOJ970101, BASU010101]):\n",
    "    res_dict = {}\n",
    "    for B in matrices:\n",
    "        key = str(B)\n",
    "        arr_ddg, arr_ei = get_ddg_ei_cp_arrays(B, comp_ei)\n",
    "        res_dict[key] = (arr_ddg, arr_ei)\n",
    "        cor_ei = pearsonr(arr_ddg, arr_ei)\n",
    "        print(\"%s: EI: %s\" % (key, cor_ei,))\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cps = grid_search_cp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cp_a_b(mut, skempi_record, C, radius):\n",
    "    return CP_A_B(mut, skempi_record, C, radius)\n",
    "\n",
    "\n",
    "def get_ddg_cp_a_b_arrays(M, func, radius=None):\n",
    "    arr_ddg = []\n",
    "    arr_obs_a = []\n",
    "    arr_obs_b = []\n",
    "    pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "    for i, row in skempi_df.iterrows():\n",
    "        ddg = row.DDG\n",
    "        arr_ddg.append(ddg)\n",
    "        arr_obs_mut_a = []\n",
    "        arr_obs_mut_b = []\n",
    "        for mutation in row[\"Mutation(s)_cleaned\"].split(','):\n",
    "            mut = Mutation(mutation)\n",
    "            t = tuple(row.Protein.split('_'))\n",
    "            skempi_record = skempi_records[t]\n",
    "            obs_a, obs_b = func(mut, skempi_record, M, radius)\n",
    "            arr_obs_mut_a.append(obs_a)\n",
    "            arr_obs_mut_b.append(obs_b)\n",
    "        arr_obs_a.append(np.sum(arr_obs_mut_a))\n",
    "        arr_obs_b.append(np.sum(arr_obs_mut_b))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return arr_ddg, arr_obs_a, arr_obs_b\n",
    "\n",
    "\n",
    "def grid_search_cp_a_b(matrices=[SKOJ970101, BASU010101], radiuses=[4, 5, 6, 7, 8, 9, 10]):\n",
    "    res_dict = {}\n",
    "    for C, angs in product(matrices, radiuses):\n",
    "        key = (str(C), angs)\n",
    "        arr_ddg, arr_cp_a, arr_cp_b  = get_ddg_cp_a_b_arrays(C, comp_cp_a_b, angs)\n",
    "        arr_cp = np.asarray(arr_cp_a) + np.asarray(arr_cp_b)\n",
    "        res_dict[key] = (arr_ddg, arr_cp_a, arr_cp_b)\n",
    "        cor_cp_a = pearsonr(arr_ddg, arr_cp_a)\n",
    "        cor_cp_b = pearsonr(arr_ddg, arr_cp_b)\n",
    "        cor_cp = pearsonr(arr_ddg, arr_cp)\n",
    "        print(\"%s: CP_A: %s, CP_B: %s, CP %s\" % (key, cor_cp_a, cor_cp_b, cor_cp))\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_A_B(mut, skempi, C, radius=6):\n",
    "    \n",
    "    i, chain_a = mut.i, mut.chain_id\n",
    "    m, w = mut.m, mut.w\n",
    "    \n",
    "    def helper(P, j):\n",
    "        return sum([P[(j, a)] * (C[(a, m)] - C[(a, w)]) for a in amino_acids])\n",
    "    \n",
    "    retA, retB = 0, 0\n",
    "    for chain_b, j in skempi.get_sphere_indices(chain_a, i,radius):\n",
    "\n",
    "        a = skempi[chain_b][j].name\n",
    "        if j == i and chain_b == chain_a:\n",
    "            assert a == w\n",
    "            continue\n",
    "                \n",
    "        P = skempi.get_profile(chain_b) \n",
    "\n",
    "        if chain_b == chain_a:  \n",
    "            retA += helper(P, j)\n",
    "        \n",
    "        else:\n",
    "            retB += helper(P, j)\n",
    "    \n",
    "    return retA, retB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_a_b_s_orig = grid_search_cp_a_b(matrices=[SKOJ970101, BASU010101], radiuses=[4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_A_B(mut, skempi, C, radius=6):\n",
    "    \n",
    "    i, chain_a = mut.i, mut.chain_id\n",
    "    m, w = mut.m, mut.w\n",
    "    \n",
    "    def helper(a, j):\n",
    "        return C[(a, m)] - C[(a, w)]\n",
    "    \n",
    "    retA, retB = 0, 0\n",
    "    for chain_b, j in skempi.get_sphere_indices(chain_a, i, radius):\n",
    "\n",
    "        a = skempi[chain_b][j].name\n",
    "        if j == i and chain_b == chain_a:\n",
    "            assert a == w\n",
    "            continue\n",
    "                \n",
    "        P = skempi.get_profile(chain_b) \n",
    "\n",
    "        if chain_b == chain_a:  \n",
    "            retA += helper(a, j)\n",
    "        \n",
    "        else:\n",
    "            retB += helper(a, j)\n",
    "    \n",
    "    return retA, retB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_a_b_s_no_profile = grid_search_cp_a_b(matrices=[BASU010101], radiuses=[2.5, 3.75, 5.0, 6.25, 7.5, 8.75, 10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_A_B(mut, skempi, C, radius=6):\n",
    "    \n",
    "    i, chain_a = mut.i, mut.chain_id\n",
    "    m, w = mut.m, mut.w\n",
    "    \n",
    "    def helper(P, j):\n",
    "        return sum([0.05 * (C[(a, m)] - C[(a, w)]) for a in amino_acids])\n",
    "    \n",
    "    retA, retB = 0, 0\n",
    "    for chain_b, j in skempi.get_sphere_indices(chain_a, i,radius):\n",
    "\n",
    "        a = skempi[chain_b][j].name\n",
    "        if j == i and chain_b == chain_a:\n",
    "            assert a == w\n",
    "            continue\n",
    "                \n",
    "        P = skempi.get_profile(chain_b) \n",
    "\n",
    "        if chain_b == chain_a:  \n",
    "            retA += helper(P, j)\n",
    "        \n",
    "        else:\n",
    "            retB += helper(P, j)\n",
    "    \n",
    "    return retA, retB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp_a_b_s_uniform = grid_search_cp_a_b(matrices=[SKOJ970101, BASU010101], radiuses=[6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eis = grid_search_ei(matrices=[BLOSUM62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_cp_a_b(cp_a_b, prefix):\n",
    "    for key, val in cp_a_b.iteritems():\n",
    "        _, cp_a, cp_b = val\n",
    "        mat, rad = key\n",
    "        all_features[(prefix, \"CP_A\", mat, rad)] = cp_a\n",
    "        all_features[(prefix, \"CP_B\", mat, rad)] = cp_b\n",
    "        \n",
    "def register_cp_a_b_shells(cp_a_b, prefix):\n",
    "    for key, val in cp_a_b.iteritems():\n",
    "        _, cp_a, cp_b = val\n",
    "        mat, inner, outer = key\n",
    "        all_features[(prefix, \"CP_A\", mat, inner, outer)] = cp_a\n",
    "        all_features[(prefix, \"CP_B\", mat, inner, outer)] = cp_b\n",
    "        all_features[(prefix, \"CP\", mat, inner, outer)] = np.sum([cp_a, cp_b], axis=0)\n",
    "        \n",
    "def register_eis(eis):\n",
    "    for key, val in eis.iteritems():\n",
    "        _, ei = val\n",
    "        all_features[(\"EI\", key)] = ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_A_B(mut, skempi, C, inner, outer):\n",
    "    \n",
    "    i, chain_a = mut.i, mut.chain_id\n",
    "    m, w = mut.m, mut.w\n",
    "    \n",
    "    retA, retB = 0, 0\n",
    "    for chain_id, j in skempi.get_shell_indices(chain_a, i, inner, outer):\n",
    "\n",
    "        a = skempi[chain_id][j].name\n",
    "        if j == i and chain_id == chain_a:\n",
    "            assert a == w\n",
    "            continue\n",
    "                \n",
    "        P = skempi.get_profile(chain_id) \n",
    "\n",
    "        if chain_id == chain_a:  \n",
    "            retA += C[(a, m)] - C[(a, w)]\n",
    "        else:\n",
    "            retB += C[(a, m)] - C[(a, w)]\n",
    "    \n",
    "    return retA, retB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cp_a_b_array(M, inner, outer):\n",
    "    arr_obs_a = []\n",
    "    arr_obs_b = []\n",
    "    pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "    for i, row in skempi_df.iterrows():\n",
    "        arr_obs_mut_a = []\n",
    "        arr_obs_mut_b = []\n",
    "        for mutation in row[\"Mutation(s)_cleaned\"].split(','):\n",
    "            mut = Mutation(mutation)\n",
    "            t = tuple(row.Protein.split('_'))\n",
    "            skempi_record = skempi_records[t]\n",
    "            obs_a, obs_b = CP_A_B(mut, skempi_record, M, inner, outer)\n",
    "            arr_obs_mut_a.append(obs_a)\n",
    "            arr_obs_mut_b.append(obs_b)\n",
    "        arr_obs_a.append(np.sum(arr_obs_mut_a))\n",
    "        arr_obs_b.append(np.sum(arr_obs_mut_b))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return arr_obs_a, arr_obs_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [BASU010101]\n",
    "shells = [(0.0, 2.0), (2.0, 4.0), (4.0, 6.0), (6.0, 8.0)]\n",
    "\n",
    "def grid_search_cp(matrices=matrices, shells=shells):\n",
    "    res_dict = {}\n",
    "    grid = [(mat, shell) for mat in matrices for shell in shells]\n",
    "    for mat, (inner, outer) in grid:\n",
    "        arr_cp_a, arr_cp_b  = get_cp_a_b_array(mat, inner, outer)\n",
    "        arr_cp = np.asarray(arr_cp_a) + np.asarray(arr_cp_b)\n",
    "        arr_ddg = skempi_df.DDG\n",
    "        cor_cp_a = pearsonr(arr_ddg, arr_cp_a)\n",
    "        cor_cp_b = pearsonr(arr_ddg, arr_cp_b)\n",
    "        cor_cp = pearsonr(arr_ddg, arr_cp)\n",
    "        key = (str(mat), inner, outer)\n",
    "        res_dict[key] = (arr_ddg, arr_cp_a, arr_cp_b)\n",
    "        print(\"%s: CP_A: %s, CP_B: %s, CP %s\" % (key, cor_cp_a, cor_cp_b, cor_cp))\n",
    "    return res_dict\n",
    "\n",
    "cp_a_b_s_shells = grid_search_cp(matrices, shells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_cp_a_b(cp_a_b_s_uniform, \"uniform\")\n",
    "# register_cp_a_b(cp_a_b_s_orig, \"original\")\n",
    "# register_cp_a_b(cp_a_b_s_no_profile, \"no_profile\")\n",
    "register_cp_a_b_shells(cp_a_b_s_shells, \"shells\")\n",
    "register_eis(eis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_muts = np.asarray([len(mut.split(\",\")) for mut in skempi_df[\"Mutation(s)_cleaned\"]])\n",
    "pearsonr(skempi_df.DDG, np.log(num_muts)), pearsonr(skempi_df.DDG, num_muts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features[\"#mutations\"] = np.log(num_muts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stride_array(func, agg=np.sum):\n",
    "    arr_stride = []\n",
    "    pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "    for i, row in skempi_df.iterrows():\n",
    "        arr_obs_mut = []\n",
    "        for mutation in row[\"Mutation(s)_cleaned\"].split(','):\n",
    "            mut = Mutation(mutation)\n",
    "            res_i, chain_id = mut.i, mut.chain_id\n",
    "            t = tuple(row.Protein.split('_'))\n",
    "            skempi_record = skempi_records[t]\n",
    "            d_asa = skempi_record.stride[(chain_id, res_i)]\n",
    "            obs = func(d_asa)\n",
    "            arr_obs_mut.append(obs)\n",
    "        total = skempi_record.stride._total\n",
    "        arr_stride.append((agg(arr_obs_mut), total))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return arr_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asa_arr_mutated, asa_arr_total = zip(*get_stride_array(lambda stride: stride[\"ASA_Chain\"]-stride[\"ASA\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features[\"sum(ASA_Chain-ASA):mutated\"] = asa_arr_mutated\n",
    "pearsonr(skempi_df.DDG, asa_arr_mutated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features[\"sum(ASA_Chain-ASA):total\"] = asa_arr_total\n",
    "pearsonr(skempi_df.DDG, asa_arr_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_array(mat, agg=np.mean):\n",
    "    arr = []\n",
    "    pbar = tqdm(range(len(skempi_df)), desc=\"row processed\")\n",
    "    for i, row in skempi_df.iterrows():\n",
    "        arr_obs_mut = []\n",
    "        for mutation in row[\"Mutation(s)_cleaned\"].split(','):\n",
    "            mut = Mutation(mutation)\n",
    "            res_i, chain_id = mut.i, mut.chain_id\n",
    "            t = tuple(row.Protein.split('_'))\n",
    "            skempi_record = skempi_records[t]\n",
    "            res = skempi_record[chain_id][res_i]\n",
    "            desc = mat[mut.m] - mat[mut.w]\n",
    "            arr_obs_mut.append(desc)\n",
    "        arr.append(agg(arr_obs_mut))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = FASG760101\n",
    "mol_arr = get_desc_array(M, np.mean)\n",
    "all_features[\"MolWeight\"] = mol_arr\n",
    "pearsonr(mol_arr, skempi_df.DDG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = ARGP820101\n",
    "hyd_arr = get_desc_array(H, np.mean)\n",
    "all_features[\"Hydrophobic\"] = hyd_arr\n",
    "pearsonr(hyd_arr, skempi_df.DDG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSSP = [\"G\", \"H\", \"I\", \"T\", \"E\", \"B\", \"S\", \"C\"]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "lb.fit(DSSP) \n",
    "\n",
    "def get_bin_ss(stride):\n",
    "    return lb.transform([stride[\"SS\"]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "ss_arr, _ = zip(*get_stride_array(get_bin_ss, agg=lambda a: np.sum(a, axis=0)))\n",
    "n_components = 3\n",
    "ss_arr = PCA(n_components=n_components).fit_transform(ss_arr)\n",
    "[pearsonr(skempi_df.DDG, np.asarray(ss_arr)[:, j]) for j in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XCor(object):\n",
    "    \n",
    "    def __init__(self, all_features):\n",
    "        self.feat_name_to_indx = {key:i for i, key in enumerate(all_features.keys())}\n",
    "        self.xcor_mat = np.corrcoef(np.asarray(all_features.values()))\n",
    "        \n",
    "    def __getitem__(self, t):\n",
    "        feat1, feat2 = t\n",
    "        i = self.feat_name_to_indx[feat1]\n",
    "        j = self.feat_name_to_indx[feat2]\n",
    "        return self.xcor_mat[(i, j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcor = XCor(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def search_min_xcor(all_features, th=0.05):\n",
    "    acc = set()\n",
    "    for comb in itertools.combinations(all_features.keys(), 2):\n",
    "        feat1, feat2 = comb\n",
    "        rho = xcor[(feat1, feat2)]\n",
    "        if abs(rho) < th:\n",
    "            acc.add(feat1)\n",
    "            acc.add(feat2)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_feats = search_min_xcor(all_features)\n",
    "len(acc_feats), acc_feats\n",
    "acc_feats = {\n",
    "  '#mutations',\n",
    "  'B-factor',\n",
    "  'Hydrophobic',\n",
    "  'MolWeight',\n",
    "  'sum(ASA_Chain-ASA):mutated',\n",
    "  ('EI', 'BLOSUM62'),\n",
    "#   ('shells', 'CP_A', 'BASU010101', 0.0, 2.0),\n",
    "  ('shells', 'CP_A', 'BASU010101', 2.0, 4.0),\n",
    "  ('shells', 'CP_A', 'BASU010101', 4.0, 6.0),\n",
    "#   ('shells', 'CP_B', 'BASU010101', 6.0, 8.0),\n",
    "#   ('shells', 'CP_B', 'BASU010101', 0.0, 2.0),\n",
    "  ('shells', 'CP_B', 'BASU010101', 2.0, 4.0),\n",
    "  ('shells', 'CP_B', 'BASU010101', 4.0, 6.0),\n",
    "#   ('shells', 'CP_B', 'BASU010101', 6.0, 8.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose([all_features[feat] for feat in acc_feats])\n",
    "# X = np.concatenate([X, np.asarray(ss_arr)], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def records_to_xy(skempi_records, load_neg=False):\n",
    "    data = []\n",
    "    for record in tqdm(skempi_records, desc=\"records processed\"):\n",
    "        r = record\n",
    "        assert r.struct is not None\n",
    "        data.append([r.features(True), [r.ddg], [r.group, r.is_minus]])\n",
    "        if not load_neg:\n",
    "            continue\n",
    "    X, y, ix = [np.asarray(d) for d in zip(*data)]\n",
    "    return X, y, ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skempi_structs = load_skempi_structs(\"../data/pdbs\", compute_dist_mat=False)\n",
    "skempi_records = load_skempi_records(skempi_structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_, ix_ = records_to_xy(skempi_records, load_neg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_[:, :]\n",
    "X = np.concatenate([X.T, [temp_arr]], axis=0).T\n",
    "y = y_[:, 0]\n",
    "ix = ix_\n",
    "X.shape, y.shape, ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = skempi_df\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations as comb\n",
    "\n",
    "def run_cv_test(X, get_regressor, normalize=0):\n",
    "    gt, preds, cors = [], [], []\n",
    "    groups = [G1, G2, G3, G4, G5]\n",
    "    prots = G1 + G2 + G3 + G4 + G5\n",
    "    for pair in comb(range(len(groups)), 2):\n",
    "        group = groups[pair[0]] + groups[pair[1]]\n",
    "#         rest = list(set(prots) - set(group))\n",
    "        indx_tst = df.Protein.isin(group)\n",
    "#         indx_trn = df.Protein.isin(rest)\n",
    "        indx_trn = np.logical_not(indx_tst)\n",
    "        y_trn = df.DDG[indx_trn]\n",
    "        y_true = df.DDG[indx_tst]\n",
    "        X_trn = X[indx_trn]\n",
    "        X_tst = X[indx_tst]\n",
    "        regressor = get_regressor()\n",
    "        if normalize == 1:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_trn)\n",
    "            X_trn, X_tst = scaler.transform(X_trn), scaler.transform(X_tst)\n",
    "        regressor.fit(X_trn, y_trn)\n",
    "        y_pred = regressor.predict(X_tst)\n",
    "        cor, _ = pearsonr(y_true, y_pred)\n",
    "        print(\"G%d\" % (pair[0]+1), \"G%d\" % (pair[1]+1), \"%.3f\" % cor)\n",
    "        cors.append(cor)\n",
    "        preds.extend(y_pred)\n",
    "        gt.extend(y_true)\n",
    "    return gt, preds, cors\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def get_regressor(): return RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "gt, preds, cors = run_cv_test(X, get_regressor, normalize=1)\n",
    "print(\"%.3f\" % np.mean(cors))\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "def get_regressor(): return SVR(kernel='rbf')\n",
    "gt, preds, cors = run_cv_test(X, get_regressor, normalize=1)\n",
    "print(\"%.3f\" % np.mean(cors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_test(X, alpha=0.5, normalize=1):\n",
    "    gt, preds, cors = [], [], []\n",
    "    groups = [G1, G2, G3, G4, G5]\n",
    "    prots = G1 + G2 + G3 + G4 + G5\n",
    "    for pair in comb(range(NUM_GROUPS), 2):\n",
    "        group = groups[pair[0]] + groups[pair[1]]\n",
    "#         rest = list(set(prots) - set(group))\n",
    "        indx_tst = df.Protein.isin(group)\n",
    "#         indx_trn = df.Protein.isin(rest)\n",
    "        indx_trn = np.logical_not(indx_tst)\n",
    "        y_trn = df.DDG[indx_trn]\n",
    "        y_true = df.DDG[indx_tst]\n",
    "        X_trn = X[indx_trn]\n",
    "        X_tst = X[indx_tst]\n",
    "        rf = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "        svr = SVR(kernel='rbf')\n",
    "        if normalize == 1:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_trn)\n",
    "            X_trn, X_tst = scaler.transform(X_trn), scaler.transform(X_tst)\n",
    "        svr.fit(X_trn, y_trn)\n",
    "        rf.fit(X_trn, y_trn)\n",
    "        y_pred_svr = svr.predict(X_tst)\n",
    "        y_pred_rf = rf.predict(X_tst)\n",
    "        y_pred = alpha * y_pred_svr + (1-alpha) * y_pred_rf\n",
    "        cor, _ = pearsonr(y_true, y_pred)\n",
    "        print(\"G%d\" % (pair[0]+1), \"G%d\" % (pair[1]+1), \"%.3f\" % cor)\n",
    "        cors.append(cor)\n",
    "        preds.extend(y_pred)\n",
    "        gt.extend(y_true)\n",
    "    return gt, preds, cors\n",
    "\n",
    "\n",
    "gt, preds, cors = run_cv_test(X, normalize=1)\n",
    "print(\"%.3f\" % np.mean(cors))\n",
    "len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skempi2",
   "language": "python",
   "name": "skempi2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
